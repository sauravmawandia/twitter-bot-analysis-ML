{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms for Twitter Bot Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.mlab import PCA\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data from The CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "twitterBots = pd.read_csv('../data/bots_data.csv',encoding='latin-1')\n",
    "twitterNonBots=pd.read_csv('../data/nonbots_data.csv',encoding='latin-1')\n",
    "user=pd.read_csv('../data/training_data_2_csv_UTF.csv',encoding='latin-1')\n",
    "test=pd.read_csv('../data/test_data_4_students.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Training Data and converting it to boolean & numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>listedcount</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>lang</th>\n",
       "      <th>status</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>default_profile_image</th>\n",
       "      <th>has_extended_profile</th>\n",
       "      <th>name</th>\n",
       "      <th>bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.160000e+17</td>\n",
       "      <td>\"815745789754417152\"</td>\n",
       "      <td>False</td>\n",
       "      <td>\"Houston, TX\"</td>\n",
       "      <td>False</td>\n",
       "      <td>\"https://t.co/dnWuDbFRkt\"</td>\n",
       "      <td>1291</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Mon Jan 02 02:25:26 +0000 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>78554</td>\n",
       "      <td>\"en\"</td>\n",
       "      <td>{\\r      \"created_at\": \"Sun Mar 12 15:44:04 +0...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.843621e+09</td>\n",
       "      <td>4843621225</td>\n",
       "      <td>False</td>\n",
       "      <td>Templeville town, MD, USA</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>349</td>\n",
       "      <td>0</td>\n",
       "      <td>2/1/2016 7:37</td>\n",
       "      <td>38</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "      <td>en</td>\n",
       "      <td>null</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.303727e+09</td>\n",
       "      <td>4303727112</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>https://t.co/P1e1o0m4KC</td>\n",
       "      <td>1086</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>Fri Nov 20 18:53:22 +0000 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>713</td>\n",
       "      <td>en</td>\n",
       "      <td>{'retweeted': False, 'is_quote_status': False,...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.063139e+09</td>\n",
       "      <td>3063139353</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2/25/2015 20:11</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>676</td>\n",
       "      <td>en</td>\n",
       "      <td>Construction of human anti-tetanus single-chai...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.955142e+09</td>\n",
       "      <td>2955142070</td>\n",
       "      <td>False</td>\n",
       "      <td>Dublin, United States</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>745</td>\n",
       "      <td>0</td>\n",
       "      <td>1/1/2015 17:44</td>\n",
       "      <td>146</td>\n",
       "      <td>False</td>\n",
       "      <td>185</td>\n",
       "      <td>en</td>\n",
       "      <td>null</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                id_str screen_name                   location  \\\n",
       "0  8.160000e+17  \"815745789754417152\"       False              \"Houston, TX\"   \n",
       "1  4.843621e+09            4843621225       False  Templeville town, MD, USA   \n",
       "2  4.303727e+09            4303727112        True                        NaN   \n",
       "3  3.063139e+09            3063139353       False                        NaN   \n",
       "4  2.955142e+09            2955142070       False      Dublin, United States   \n",
       "\n",
       "  description                        url  followers_count  friends_count  \\\n",
       "0       False  \"https://t.co/dnWuDbFRkt\"             1291              0   \n",
       "1       False                        NaN                1            349   \n",
       "2        True    https://t.co/P1e1o0m4KC             1086              0   \n",
       "3       False                        NaN               33              0   \n",
       "4       False                        NaN               11            745   \n",
       "\n",
       "   listedcount                      created_at  favourites_count verified  \\\n",
       "0           10  Mon Jan 02 02:25:26 +0000 2017                 0    False   \n",
       "1            0                   2/1/2016 7:37                38    False   \n",
       "2           14  Fri Nov 20 18:53:22 +0000 2015                 0    False   \n",
       "3            8                 2/25/2015 20:11                 0    False   \n",
       "4            0                  1/1/2015 17:44               146    False   \n",
       "\n",
       "   statuses_count  lang                                             status  \\\n",
       "0           78554  \"en\"  {\\r      \"created_at\": \"Sun Mar 12 15:44:04 +0...   \n",
       "1              31    en                                               null   \n",
       "2             713    en  {'retweeted': False, 'is_quote_status': False,...   \n",
       "3             676    en  Construction of human anti-tetanus single-chai...   \n",
       "4             185    en                                               null   \n",
       "\n",
       "  default_profile default_profile_image has_extended_profile   name  bot  \n",
       "0            True                 False                False  False    1  \n",
       "1            True                 False                False  False    1  \n",
       "2            True                 False                False  False    1  \n",
       "3            True                  True                False  False    1  \n",
       "4           False                 False                False  False    1  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=user\n",
    "df['favourites_count'].replace(['None'], '0')\n",
    "df['default_profile'].replace(['None'], False)\n",
    "df['default_profile_image'].replace(['None'], False)\n",
    "df['screen_name']=df['screen_name'].str.contains('bot', na=False)\n",
    "df['name']=df['name'].str.contains('bot', na=False)\n",
    "df['description']=df['description'].str.contains('bot', na=False)\n",
    "df['created_at'] = df['created_at'].str.replace('\"', '')\n",
    "\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###  Calculating the status per day from the day account was created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['created_at']=pd.to_datetime(df['created_at'])\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "df['today']=now\n",
    "df['daysTillNow'] = df['today']-df['created_at']\n",
    "df['daysTillNow']=df['daysTillNow'].dt.days\n",
    "df['statusPerDay']=df['statuses_count']/df['daysTillNow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Cleaning Test data and doing the same work we did for Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf=test\n",
    "tf = tf.rename(columns={'favourites_count': 'favourites_count'})\n",
    "\n",
    "tf['favorites_count']=tf['favorites_count'].replace(['None'], 0)\n",
    "tf['default_profile']=tf['default_profile'].replace(['None'], False)\n",
    "tf['default_profile_image']=tf['default_profile_image'].replace(['None'], False)\n",
    "tf['favorites_count']=tf['favorites_count'].replace(['FALSE'], False)\n",
    "tf['favorites_count']=tf['favorites_count'].replace(['TRUE'], True)\n",
    "tf['favorites_count']=tf['favorites_count'].replace(['None'], False)\n",
    "tf['default_profile']=tf['default_profile'].replace(['FALSE'], False)\n",
    "tf['default_profile']=tf['default_profile'].replace(['TRUE'], True)\n",
    "tf['default_profile']=tf['default_profile'].replace(['None'], False)\n",
    "tf['default_profile_image']=tf['default_profile_image'].replace(['FALSE'], False)\n",
    "tf['default_profile_image']=tf['default_profile_image'].replace(['TRUE'], True)\n",
    "tf['default_profile_image']=tf['default_profile_image'].replace(['None'], False)\n",
    "tf['verified']=tf['verified'].replace(['TRUE'], True)\n",
    "tf['verified']=tf['verified'].replace(['FALSE'], False)\n",
    "tf['verified']=tf['verified'].replace(['None'], False)\n",
    "tf['followers_count']=tf['followers_count'].replace(['None'], 0)\n",
    "tf['friends_count']=tf['friends_count'].replace(['None'], 0)\n",
    "tf['statuses_count']=tf['statuses_count'].replace(['None'], 0)\n",
    "tf['screen_name']=tf['screen_name'].str.contains('bot', na=False)\n",
    "tf['name']=tf['name'].str.contains('bot', na=False)\n",
    "tf['description']=tf['description'].str.contains('bot', na=False)\n",
    "tf['created_at'] = tf['created_at'].str.replace('\"', '')\n",
    "tf['created_at']=pd.to_datetime(tf['created_at'])\n",
    "tf['today']=now\n",
    "tf['daysTillNow'] = tf['today']-tf['created_at']\n",
    "tf['daysTillNow']=tf['daysTillNow'].dt.days\n",
    "tf['statusPerDay']=tf['statuses_count']/tf['daysTillNow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df[['followers_count','screen_name',\n",
    "                                                        'friends_count','description','verified','statusPerDay',\n",
    "                                                        'favourites_count','default_profile','default_profile_image','name']],df['bot'] ,test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testData=tf[['followers_count','friends_count','description',\n",
    "             'verified',\n",
    "             'favorites_count','statusPerDay','default_profile_image','default_profile','name']]\n",
    "testData=testData[:575]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing which feature will help in our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.41810000000000003, 'friends_count'), (0.221, 'followers_count'), (0.14680000000000001, 'statusPerDay'), (0.093899999999999997, 'verified'), (0.074300000000000005, 'favourites_count'), (0.023300000000000001, 'description'), (0.0088000000000000005, 'default_profile_image'), (0.0076, 'default_profile'), (0.0054000000000000003, 'screen_name'), (0.00069999999999999999, 'name')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, Y_train)\n",
    "print (\"Features sorted by their score:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_),X_train.columns.values.tolist()), \n",
    "             reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the training data  and predicting test data contained in training data and the test data from Kaggle using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForest is 89.6428571429 %\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.91      0.90       435\n",
      "          1       0.90      0.89      0.89       405\n",
      "\n",
      "avg / total       0.90      0.90      0.90       840\n",
      "\n",
      "AUC Score for Random forest is 0.896083439762\n"
     ]
    }
   ],
   "source": [
    "clf=RandomForestClassifier(n_estimators=175,max_features=3,min_samples_leaf=10)\n",
    "model= clf.fit(X_train,Y_train)\n",
    "predicted=model.predict(X_test)\n",
    "predictedTest=model.predict(testData)\n",
    "print('Accuracy of RandomForest is',accuracy_score(Y_test,predicted)*100,'%')\n",
    "print(metrics.classification_report(Y_test,predicted))\n",
    "print('AUC Score for Random forest is',metrics.roc_auc_score(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Decision tree to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree 86.1904761905 %\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.85      0.86       435\n",
      "          1       0.84      0.87      0.86       405\n",
      "\n",
      "avg / total       0.86      0.86      0.86       840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(X_train, Y_train)\n",
    "predictedDT=dt.predict(X_test)\n",
    "print('Accuracy of Decision Tree',accuracy_score(Y_test,predictedDT)*100,'%')\n",
    "print(metrics.classification_report(Y_test,predictedDT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Clearly Random forest give us a higher accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction For Kaggle test data and turning it in to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=test[:575]\n",
    "output['bot']=predictedTest\n",
    "predictedTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nf=output[['id','bot']]\n",
    "nf.to_csv('test.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
